---
title: "[TensorFloW] Tensor 소개"
layout: single

toc: true
data: 2021-10-04
---

## TensorFlow란?

TensorFlow는 구글에서 개발한 머신러닝을 위한 오픈소스 라이브러리이다.

## 텐서(Tensor)?

TensorFlow에서 Tensor는 학습 데이터가 저장되는 일관된 유형의 다차원 배열을 의미한다. TensorFlow 내부의 모든 데이터는 Tensor로 표현된다.

## 텐서와 관련된 개념들

### Rank

Tensor의 Rank는 차원의 수이다. 즉, 몇 차원의 배열이냐는 의미이다.

|Rank|Math Entity|Example|
|:---:|:---:|:---:|
|0|Scalar|[1]|
|1|Vector|[1, 2, 3]|
|2|Matrix|[[1, 2, 3], [1, 2, 3], [1, 2, 3]|
|3|3-Tensor|[[[1], [2], [3]], [[4], [5], [6]], [[7], [8], [9]]]|
|n|n-Tensor|...|

Scalar는 0차원 배열로 일반적으로 존재하는 단일 값이다.

### Shape

Tensor의 Shape은 각 차원의 길이, 즉 요소(Element)의 수를 의미한다. 각 축이 몇 개의 요소들로 구성되었는지 나타내는 값이다.\
예를 들어, scalar의 shape은 []이다. Rank가 1인 벡터의 shape이 [3]이라면 엘리먼트(Element)가 3개인 벡터를 나태고, shape이 [2, 3]이면 Rank가 2이고 각 축이 3개의 요소를 갖는 2 * 3 행렬을 의미한다.

### Size

Tensor 내 총 항목의 개수이다. 

### Type

텐서에 담기는 데이터의 타입. float와 int가 주로 담기지만, 복소수와 문자열도 담을 수 있다.

## Indexing

### Single-axis indexing

TensorFlow는 기존 파이썬의 list와 string의 indexing 규칙을 따른다.

* 인덱스는 0에서 시작한다.
* 음수 인덱스는 끝에서부터 계산한다.
* `:`(colon)은 슬라이스에 사용된다.

```
rank_1_tensor = tf.constant([0, 1, 2, 5, 12, 19, 20, 31, 21, 33])
print(rank_1_tensor.numpy())
```
```
[ 0  1  2  5 12 19 20 31 21 33]
```
인덱싱에 단일 값만 사용하면 그 값에 해당하는 인덱스에 접근.
```
print("First:", rank_1_tensor[0].numpy())
print("Second:", rank_1_tensor[1].numpy())
print("Last:", rank_1_tensor[-1].numpy())
```
```
First: 0
Second: 1
Last: 33
```

':' 슬라이싱을 이용하여 축의 일부에 접근할 수 있다.
```
print("Everything:", rank_1_tensor[:].numpy())
print("Before 4:", rank_1_tensor[:4].numpy())
print("From 4 to the end:", rank_1_tensor[4:].numpy())
print("From 2, before 7:", rank_1_tensor[2:7].numpy())
print("Every other item:", rank_1_tensor[::2].numpy())
print("Reversed:", rank_1_tensor[::-1].numpy())
```
```
Everything: [ 0  1  2  5 12 19 20 31 21 33]
Before 4: [0 1 2 5]
From 4 to the end: [12 19 20 31 21 33]
From 2, before 7: [ 2  5 12 19 20]
Every other item: [ 0  2 12 20 21]
Reversed: [33 21 31 20 19 12  5  2  1  0]
```
### Multi-axis indexing

```
rank_2_tensor = tf.constant([[1, 2],
                             [3, 4],
                             [5, 6]], dtype=tf.float16)
print(rank_2_tensor.numpy())
```
```
[[1. 2.]
 [3. 4.]
 [5. 6.]]
```
 
각 축의 인덱스 걊을 각각 입력하여 특정 인덱스에 접근.
```
print(rank_2_tensor[1, 1].numpy())
```
```
 4.0
```
 
정수와 슬라이싱을 이용하여 일부 인덱스에 접근할 수 있다.

```
print("Second row:", rank_2_tensor[1, :].numpy())
print("Second column:", rank_2_tensor[:, 1].numpy())
print("Last row:", rank_2_tensor[-1, :].numpy())
print("First item in last column:", rank_2_tensor[0, -1].numpy())
print("Skip the first row:")
print(rank_2_tensor[1:, :].numpy(), "\n")
```
```
Second row: [3. 4.]
Second column: [2. 4. 6.]
Last row: [5. 6.]
First item in last column: 2.0
Skip the first row:
[[3. 4.]
 [5. 6.]] 
```

## 텐서의 Shape 조작

텐서의 shape을 변형하는 함수를 사용할 수 있다.

`tf.reshape(tensor, shape, name=None)`

위 함수는 해당 `tensor`와 같은 원소들을 가지며,  구조가 `shape`인 텐서를 반환한다.

```
var_x = tf.Variable(tf.constant([[1], [2], [3]]))
print(var_x.shape)
```
```
(3, 1)
```
```
reshaped = tf.reshape(var_x, [1, 3])
print(reshaped.shape)
```
```
(1,3)
```

## `DTypes`

`tf.Tensor`의 데이터 유형을 검사하려면, `Tensor.dtype` 속성을 사용한다. TensorFlow는 Python 정수를 `tf.int32`로, Python 부동 소수점 숫자를 `tf.float32`로 변환한다.

```
the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)
the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_u8_tensor)
```
```
tf.Tensor([2 3 4], shape=(3,), dtype=uint8)
```

## Broadcasting

브로드캐스팅은 NumPy의 해당 특성에서 빌린 개념이다. 연산 시 두 텐서 중 크기가 작은 텐서를 크기가 큰 텐서와 shape이 맞게끔 자동으로 확장시켜준다.

```
x = tf.constant([1, 2, 3])
y = tf.constant(2)
z = tf.constant([2, 2, 2])

print(tf.multiply(x, 2))
print(x * y)
print(x * z)
```
```
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
```

3x1 행렬에 요소별로 1x4 행렬을 곱하여 3x4 행렬을 만든다.

```
x = tf.reshape(x,[3,1])
y = tf.range(1, 5)
print(x, "\n")
print(y, "\n")
print(tf.multiply(x, y))
```
```
tf.Tensor(
[[1]
 [2]
 [3]], shape=(3, 1), dtype=int32) 

tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) 

tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
 ```

## 그 외의 Tensor

### Ragged Tensors (비정형 텐서)

어떤 축을 따라 다양한 수의 요소를 가진 텐서를 "ragged(비정형)"이라고 한다. 비정형 데이터에는 `tf.ragged.RaggedTensor`를
사용한다. 비정형 텐서는 정규 텐서로 표현할 수 없고 `tf.ragged.constant`를 사용하여 `tf.RaggedTensor`를 작성할 수 있다.

```
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)
```
```
<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>
```

tf.RaggedTensor의 형상에는 알 수 없는 길이의 일부 축이 포함된다.

```
print(ragged_tensor.shape)
```
```
(4, None)
```

### String tensors (문자열 텐서)

`tf.string`은 dtype이며, 텐서에서 문자열(가변 길이의 바이트 배열)과 같은 데이터를 나타낼 수 있다. 문자열은 Python 문자열과 같은 방식으로 인덱싱할 수 없다.
```
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)
```
```
tf.Tensor(b'Gray wolf', shape=(), dtype=string)
```
서로 다른 길이의 문자열 텐서도 가능하며, shape에 문자열 길이는 포함되지 않는다.
```
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
print(tensor_of_strings)
```
```
tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)
```
위의 출력에서 b 접두사는 `tf.string dtype`이 유니코드 문자열이 아니라 바이트 문자열임을 나타낸다.

### Sparse tensors (희소 텐서)

TensorFlow는 희소 텐서(대부분 0으로 채워진 텐서)를 효율적으로 표현할 수 있다. `tf.sparse.SparseTensor` 및 관련 연산을 지원하여 희소 데이터를 효율적으로 저장한다. 텐서의 크기와 0이 아닌 원소의 인덱스와 값을 지정한다.

```
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")
print(tf.sparse.to_dense(sparse_tensor))
```
```
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 

tf.Tensor(
[[1 0 0 0]
 [0 0 2 0]
 [0 0 0 0]], shape=(3, 4), dtype=int32)
```
