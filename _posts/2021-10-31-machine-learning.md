---
layout: single
title: "Workflow of machine learning"
excerpt: "The process of dealing with machine learning problems."

toc: true
toc_sticky: true

date: 2021-10-31
---

'The universal workflow of machine learning'에서는 머신러닝에 접근하고 문제를 해결하는 데 사용할 수 있는 보편적인 단계에 대해 알아보겠습니다.

머신러닝의 보편적 워크플로는 크게 세 부분으로 구성됩니다.

- 문제의 정의: 문제 영역과 고객이 질문한 내용을 뒷받침하는 비즈니스 논리를 이해합니다. 데이터 세트를 수집하고, 데이터가 나타내는 바를 파악한 후, 작업에서 성공을 측정하는 방법을 선택합니다.
- 모델 개발: 머신러닝 모델에서 데이터를 처리할 수 있도록 준비하고, 모델 평가 프로토콜과 이길 수 있는 간단한 기준선을 선택한 다음, 오버핏할 수 있는 일반화 능력을 갖춘 첫 번째 모델을 교육한 다음, 최대한의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정합니다.
- 모델 배치: 이해 관계자에게 작업물을 전달하고, 여러 종류의 장치로 모델을 전달하며, 모델 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집합니다.

## 1. Define the task

### 1.1 Frame the problem 

기계 학습 문제를 구체화하려면 일반적으로 이해관계자들과의 많은 상세한 논의가 필요합니다. 이 과정에서 필요한 질문들이 있습니다.

- 입력 데이터는 어떻게 되는가? 무엇을 예측하려고 하는가? 이 단계에서 데이터 가용성은 보통 제한 요소입니다. 대부분의 경우 사용자가 직접 새 데이터셋을 수집하고 주석을 달아야 합니다.
- 어떤 종류의 기계 학습 문제인가? (이항 분류, 다중 클래스 분류, 스칼라 회귀, 벡터 회귀, 멀티클래스, 멀티라벨 분류, 이미지 분할, 순위, 클러스터링, 생성 또는 강화 학습 등)
- 기존 솔루션은 어떤 형태인가? 현재 일부 분야에서는 인간이 직접 처리하는 과정 등의 수작업 알고리즘을 거칠 것입니다. 어떤 시스템이 이미 구축되어 있는지, 어떻게 작동하는지 확실히 이해해야 합니다.
- 처리해야 할 특별한 제약이 있는가? 우리는 모델이 들어맞을 전체 맥락을 이해해야 합니다.

일단 조사를 마쳤으면, 여러분의 입력이 무엇일지, 여러분의 목표가 무엇인지, 그리고 문제가 어떤 종류의 기계 학습 과제로 매핑되는지 알아야 합니다. 이 단계에서 자신이 세우는 가설에 유의하여야 합니다.

- 입력이 주어지면 목표값을 예측할 수 있다는 가설을 세웁니다.
- 사용할 수 있는 데이터(또는 곧 수집할 데이터)가 입력과 목표값 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다.

작업 모형을 갖추기 전까지는 가설일 뿐이며 검증되거나 무효화될 수 있습니다. 기계 학습으로 모든 문제를 해결할 수 있는 것은 아닙니다. 입력 X와 대상 Y의 예를 종합했다고 해서 X가 Y를 예측하기에 충분한 정보를 포함하고 있다는 것이 아니라는 의미입니다. 

### 1.2 Collect a dataset 

작업의 특성을 이해하고 입력과 대상이 무엇인지 알게 되면, 다음은 시간과 비용이 많이 드는 부분인 데이터 수집이 필요한 시점입니다.

모델의 일반화 기능은 거의 전적으로 모델의 데이터 속성, 즉 보유한 데이터 포인트 수, 레이블의 안정성, 기능의 품질에 따라 정해집니다. 좋은 데이터 세트는 관리하고 투자할 가치가 있는 자산이라고 볼 수 있습니다.

지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후에는 입력(예: 이미지 태그)에 대한 주석(예: 모델이 예측할 목표)이 필요합니다.

**Investing in data-annotation infrastructure**

데이터 주석 공정에 따라 목표물의 품질이 결정되고, 이는 다시 모형의 품질을 결정합니다. 사용할 수 있는 옵션을 신중하게 고려하여야 합니다.

- 데이터에 직접 주석을 달아야 하는가.
- 라벨을 모으기 위해 기계 터크와 같은 크라우드소싱 플랫폼을 사용해야 하는가?
- 데이터 레이블링 전문 회사의 서비스를 사용해야 하는가?

아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제력을 잃게 될 수 있습니다. 
최상의 옵션을 선택하려면 작업 중인 제약 조건을 고려해야 합니다.

- 데이터 라벨 작성자가 주제 전문가여야 하는가, 아니면 데이터에 주석을 달 수 있는 사람이 있는가
- 데이터에 주석을 달아야 하는 전문 지식이 있다면, 그것을 하도록 사람들을 훈련시킬 수 있는가? 그렇지 않다면, 관련 전문가와 어떻게 접촉할 수 있는가?
- 당신은 전문가들이 어떻게 주석을 달 수 있는지 이해하는가? 그렇지 않으면 데이터 세트를 블랙박스로 취급해야 하며 수동 기능 엔지니어링을 수행할 수 없습니다.

데이터에 레이블을 붙이기로 결정한 경우 주석을 기록하는 데 사용할 소프트웨어를 확인하여야 합니다. 직접 그 소프트웨어를 개발해야 할 경우를 대비하기 위함입니다. 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있습니다.

**Beware of non-representative data**

기계 학습 모델은 교육에 사용되는 데이터가 생산 데이터를 대표해야 합니다.
가능하면 모델이 사용될 환경에서 직접 데이터를 수집합니다. 프로덕션 데이터에 대한 교육이 가능하지 않다면 교육 데이터와 프로덕션 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 합니다.

알아야 할 관련 현상은 개념 드리프트입니다. 거의 모든 실제 문제, 특히 사용자 생성 데이터를 다루는 문제에서 개념 드리프트가 발생합니다. 개념 드리프트는 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생합니다. 빠른 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석 및 모델 재교육이 필요합니다. 기계 학습은 훈련 데이터에 존재하는 패턴을 암기하는 데만 사용될 수 있다는 것을 명심하여야 합니다. 전에 본 것만 알아볼 수 있다는 의미이다. 미래를 예측하기 위해 과거 데이터에 대해 훈련된 머신러닝을 사용하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 하는 것이며 이러한 경향은 틀릴 가능성이 있습니다.

### 1.3 Understand your data

데이터 세트를 블랙박스로 취급하는 것은 매우 나쁜 관행입니다. 모델을 교육하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고(기능 엔지니어링에 정보를 제공) 잠재적인 문제를 선별해야 합니다.

- 데이터에 이미지 또는 자연어 텍스트가 포함된 경우 몇 가지 샘플(및 해당 레이블)을 직접 살펴보기
- 데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악
- 데이터에 위치 정보가 포함되어 있으면 지도에 표시하여 뚜렷한 패턴이 있는 지 확인
- 일부 샘플에 일부 기능의 결측값이 있는지 확인 (이 경우 데이터를 준비할 때 이 문제를 해결해야 합니다)
- 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 출력. 클래스가 대략적으로 동등하게 표현되지않다면 불균형을 고려해야 합니다. 
- 목표 누출 여부: 데이터에 실운영 환경에서 사용할 수 없는 대상에 대한 정보를 제공하는 기능이 있는지 확인. 데이터의 모든 기능이 운영 환경에서도 동일한 형태로 제공되는지 확인하여야 합니다.

### 1.4 Choose a measure of success

무언가를 통제하기 위해서는 그것을 관찰할 수 있어야 합니다. 프로젝트에서 성공을 거두기 위해서는 먼저 성공의 기준을 정의해야 합니다. (정확성? 정확성과 기억력? 고객 유지율?) 성공을 위한 지표는 프로젝트 전반에 걸쳐 진행될 될 모든 기술적 선택의 기준이 될 것입니다. 고객의 비즈니스 성공과 같은 상위 수준의 목표와 직접 연계되어야 합니다. 

모든 클래스가 동일한 가능성이 있는 균형 분류 문제의 경우, 수신기 작동 특성 곡선(ROC AUC) 아래의 정확도와 영역이 일반적인 지표입니다. 클래스 불균형 문제, 순위 문제 또는 다중 레이블 분류의 경우 정밀도 및 호출뿐만 아니라 가중 형태의 정확도 또는 ROC AUC를 사용할 수 있습니다. 또한 성공을 측정하기 위해 자신만의 사용자 지정 메트릭을 정의해야 하는 경우도 흔합니다. 

## 2. Develop a model 

### 2.1 Prepare the data 

딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않습니다. 데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것입니다. 여기에는 벡터화, 정규화 또는 결측값 처리가 포함됩니다. 모든 데이터 도메인에 공통적으로 적용되는 기본 사항에 대해 살펴보겠습니다.

**Vectorization**

신경망의 모든 입력과 대상은 일반적으로 부동소수점 데이터의 텐서(또는 특정한 경우 정수나 문자열의 텐서)여야 합니다. 소리, 이미지, 텍스트 등 필요한 데이터가 무엇이든 먼저 텐서로 변환해야 합니다. 이 단계를 데이터 벡터화라고 합니다. 예를 들어, 두 텍스트 분류 예에서는 정수 목록(단어 시퀀스를 나타냄)으로 표현된 텍스트에서 원핫 인코딩을 사용하여 float32 데이터의 텐서로 변환합니다.

**Value normalization**

데이터를 네트워크에 입력하기 전에 표준 편차가 1이고 평균이 0이 되도록 각 피쳐를 독립적으로 정규화합니다. 
일반적으로 상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 사용하는 신경망 데이터나 다종의 데이터(예: 한 특징이 0-1이고 다른 특징이 100-200인 데이터)에 입력하는 것은 좋지 않습니다. 이렇게 하면 대규모 그라데이션 업데이트가 트리거되어 네트워크가 수렴되지 않을 수 있습니다. 네트워크에서 보다 쉽게 학습하려면 데이터에 다음과 같은 특성이 있어야 합니다.

- 작은 값 사용: 일반적으로 대부분의 값은 0-1 범위여야 합니다. 
- 동일화: 모든 형상이 거의 동일한 범위의 값을 가져야 합니다. 

추가적으로 다음과 같은 엄격한 정규화 방법이 일반적입니다. (항상 필요한 것은 아니지만 도움이 될 수 있습니다.)

- 평균이 o가 되도록 각 피쳐를 독립적으로 정규화합니다. 
- 표준 편차가 1이 되도록 각 피쳐를 독립적으로 정규화합니다.

**Handling missing values**

데이터에는 결측값이 있을 수 있습니다. 특성을 완전히 제거할 수도 있지만 반드시 제거할 필요는 없습니다.

- 피쳐가 범주형인 경우, "값이 누락되었습니다"를 의미하는 새 범주를 만드는 것이 안전합니다. 모델은 대상에 대해 이것이 내포하는 의미를 자동으로 학습합니다. 
- 형상이 수치적인 경우, "0"과 같은 임의의 값을 입력하는 것은 위험합니다. 형상에 의해 형성된 잠재 공간에 불연속성이 생성되어, 그것에 대해 훈련된 모델이 일반화하기가 더 어려울 수 있기 때문입니다. 대신 결측값을 데이터 집합의 기능에 대한 평균값 또는 중위값으로 바꾸는 것이 나은 방법입니다. 다른 형상의 값이 주어진 형상의 값을 예측하도록 모델을 교육할 수도 있습니다.

테스트 데이터에 범주형 결측 기능이 있을 것으로 예상되지만 네트워크가 결측값 없이 데이터에 대해 학습된 경우, 네트워크는 결측값을 무시하는 방법을 학습하지 않습니다. 이 경우 누락된 항목이 있는 교육 샘플을 인위적으로 생성해야 합니다. 일부 교육 샘플을 여러 번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 기능 중 일부를 삭제해야 합니다.

### 2.2 Choose an evaluation protocol 

모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내릴 모든 모델링 결정은 일반화 성과를 측정하기 위한 검증 지표에 의해 평가됩니다. 검증 프로토콜의 목표는 실제 프로덕션 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것입니다. 그 과정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요합니다. 

세 가지 일반적인 평가 프로토콜은 다음과 같습니다.

- 홀드아웃 유효성 검사 세트 유지 : 데이터가 많을 때 하는 방법
- K-폴드 교차 검증 수행 : 시료가 너무 적어서 홀드아웃 검증이 신뢰할 수 없을 때 올바른 선택
- K-폴드 반복 검증 실시 : 데이터가 거의 없을 때 매우 정확한 모델 평가 수행 

이 중 하나를 선택합니다. 대부분의 경우 첫 번째 방법이 충분한 효과가 있을 것입니다. 항상 검증 세트의 대표성에 유의하고 교육 세트와 검증 세트 사이에 중복 샘플이 없도록 주의합니다.

## 2.3 Beat a baseline 

모형 자체에 대한 작업을 시작하면 통계적 검정력을 달성하는 것이 초기 목표가 됩니다. 즉, 간단한 기준선을 능가할 수 있는 작은 모형을 개발하는 것입니다. 
이 단계에서 가장 중요한 세 가지 사항은 다음과 같습니다. 

- 특징 엔지니어링을 통해 유용한 정보를 제공하지 않는 특징을 걸러내고, 문제에 대한 지식을 활용하여 유용한 새로운 특징을 개발합니다. 
- 올바른 구조 선택: 어떤 유형의 모델 구조를 사용할 것인지 결정합니다. (촘촘하게 연결된 네트워크, 컨브넷, 반복적인 신경 네트워크, 트랜스포머..)
- 충분히 적합한 학습 구성 결정: 사용할 손실함수의 종류와 배치 크기와 학습률 등을 결정합니다.


**NOTE: PICKING THE RIGHT LOSS FUNCTION**

문제에 대한 성공을 측정하는 메트릭에 대해 직접 최적화하지 못하는 경우가 많습니다. 메트릭을 손실 함수로 바꾸는 쉬운 방법이 없을 때도 있습니다. 결국 손실 함수는 데이터의 작은 배치가 주어져야 하며, 역전파를 사용하여 네트워크를 훈련시킬 수 없어야 합니다.
하단의 표는 일반적인 문제 유형에 대한 마지막 계층 활성화 및 손실 함수를 선택하는 데 도움이 될 수 있습니다.

(표)

### 2.4 Scale up: develop a model that overfits 

일단 통계적 힘을 가진 모델을 얻으면, 모델이 충분히 강력하냐는 질문을 할 수 있을 것입니다. (주어진 문제를 적절하게 모델링하기에 충분한 레이어와 파라미터를 가지고 있는가?) 예를 들어, 로지스틱 회귀 분석 모형은 MNIST에 대한 통계적 검정력이 있지만 문제를 잘 해결하기에는 충분하지 않습니다. 머신러닝의 보편적인 장력은 최적화와 일반화 사이입니다. 이상적인 모델은 과소적합과 과적합, 과소용량과 과용량 사이의 경계에 서 있는 모델입니다. 이 경계가 어디에 있는지 알아내려면 먼저 경계를 넘어야 합니다. 

얼마나 큰 모델이 필요한지 알아내려면, 당신은 지나치게 적합한 모델을 개발해야 하며 이 작업은 매우 간단합니다.

1. 레이어를 추가합니다.
2. 층을 크게 만듭니다.
3. 더 많은 epochs수로 훈련합니다.

교육 손실 및 검증 손실은 물론 관심 있는 메트릭에 대한 교육 및 검증 값도 항상 모니터링합니다. 검증 데이터에 대한 모형의 성능이 저하되기 시작하면 과적합이 이루어진 것입니다.

### 2.5 Regularize and tune your model 

일반화 성능을 극대화합니다. 
이 단계에서는 모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정하고 교육하고 검증 데이터를 평가한 다음 다시 수정하고 반복합니다. 다음과 같은 몇 가지 방법을 시도해 볼 수 있습니다.

- 다른 아키텍처를 시도하거나 레이어를 추가 또는 제거합니다.
- 종기종료 추가합니다.
- 모형이 작은 경우 L1 또는 L2 정규화를 추가합니다. 
- 최적 구성을 찾기 위해 계층당 단위 수 또는 최적화 프로그램의 학습 속도 등 다양한 하이퍼 파라미터(hyperparameter)를 사용합니다.
- 더 많은 데이터를 수집하고 주석을 달거나, 더 나은 기능을 개발하거나, 정보를 제공하지 않는 기능을 제거할 수 있습니다. 

검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모형에 유출됩니다. 여러 반복에 걸쳐 체계적으로 수행되면 검증 데이터에 대해 직접 교육을 받은 모델이 없음에도 불구하고 결국 모델이 검증 프로세스에 대한 과대적합이 이루어질 수 있습니다. 이러한 결과는 평가 과정의 신뢰성을 떨어뜨립니다. 
만족스러운 모델 구성을 개발했으면 사용 가능한 모든 데이터(교육 및 검증)에 대해 최종 생산 모델을 교육하고 테스트 세트에서 마지막으로 평가해야 합니다. 테스트 세트의 성능이 검증 데이터에서 측정된 성능보다 훨씬 더 나쁜 것으로 판명되면 이는 검증 절차를 신뢰할 수 없거나 모형의 매개 변수를 조정하는 동안 검증 데이터에 과적합하기 시작했음을 의미합니다. 이 경우 K-폴드 반복 유효성 검사와 같은 보다 안정적인 평가 프로토콜로 전환할 수 있습니다.

## 3. Deploy your model 

이제 모델은 테스트 세트에 대한 최종 평가를 성공적으로 마쳤습니다. 이제 배치하고 생산적인 작업을 시작할 준비가 되었습니다.

## 3.1 Explain your work to stakeholders and set expectations 

성공과 고객 신뢰는 지속적으로 고객의 기대에 부응하거나 그 이상을 달성하는 것입니다. 실제로 제공하는 시스템은 그 그림의 절반에 불과합니다. 나머지 절반은 출시 전 적절한 기대치를 설정하는 것입니다.

AI 시스템에 대한 비전문가들의 기대는 비현실적입니다. (예를 들어, 그들은 시스템이 과제를 "이해"하고 과제 맥락에서 인간과 같은 상식을 행사할 수 있다고 기대합니다.) 이 문제를 해결하려면 모델의 오류의 몇 가지 예제를 보여 주는 것을 고려해야 합니다.

또한 특히 이전에 사람이 처리했던 프로세스의 경우 인간 수준의 성능을 기대할 수 있습니다. 대부분의 머신러닝 모델은 인간이 만든 라벨에 근접하도록 (불완전하게) 훈련되었기 때문에 거의 도달하지 못합니다. 모델 성능 기대치를 명확히 전달해야 합니다. "모델은 98%의 정확도를 가지고 있다"와 같은 추상적인 문장을 사용하는 것을 피하고 (예를 들어) 다음과 같이 말하는 것을 지향해야 합니다. 거짓 음성 비율과 거짓 양성 비율에 대해. "이러한 설정을 사용하면 부정 행위 탐지 모델은 5%의 거짓 음성 비율과 2.5%의 거짓 양성률을 갖습니다. 매일 평균 200건의 유효거래가 사기행위로 플래그가 지정돼 수작업 검토를 위해 발송되고, 평균 14건의 사기거래가 누락됐다. 평균 266건의 부정거래가 적발될 것이다." 모델의 성능 측정 기준을 비즈니스 목표와 명확하게 연관시킵니다.

또한 주요 시작 매개 변수(예: 트랜잭션에 플래그를 지정해야 하는 확률 임계값)를 선택할 것인지 관계자와 논의해야 합니다. 이러한 결정에는 비즈니스 맥락을 깊이 이해해야만 처리할 수 있는 트레이드오프가 포함됩니다.

### 3.2 Ship an inference model 

머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 Colab 노트북으로 끝나지 않습니다. 교육 중에 조작한 것과 동일한 파이썬 모델 객체를 생산에 투입하는 경우는 거의 없습니다. 

먼저 Python이 아닌 다른 것으로 모델을 내보내는 것이 좋습니다. 
- 운영 환경에서 Python을 전혀 지원하지 않을 수 있습니다. (예를 들어, 모바일 앱이나 임베디드 시스템인 경우입니다.)
- 만약 나머지 앱이 Python이 아니라면(JavaScript, C++ 등) 모델을 서비스하기 위해 Python을 사용하면 상당한 오버헤드가 발생할 수 있습니다. 

둘째, 생산 모델은 교육용이 아니라 예측 출력에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 다양한 최적화를 수행할 수 있습니다. 

### 3.3 Monitor your model in the wild 

추론 모델을 내보내고 이를 애플리케이션에 통합한 후 프로덕션 데이터에 대해 시작동을 수행했습니다. 모델이 예상대로 작동합니다. 유닛 테스트와 로깅 및 상태 모니터링 코드를 완벽하게 작성했습니다. 이제 실운영에 투입할 차례입니다. 
심지어 이것이 끝이 아닙니다. 모델을 구축한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용 및 궁극적으로 비즈니스 메트릭에 미치는 영향을 계속 모니터링해야 합니다.

- 랜덤 A/B 검정을 사용하여 모델 자체의 영향을 다른 변경으로부터 분리하는 것을 고려하십시오. 사례의 일부는 새 모형을 통과해야 하고 다른 제어 부분 집합은 이전 공정을 고수해야 합니다. 충분히 많은 사례가 처리되면, 두 사례의 결과 차이는 모델에 기인할 가능성이 높습니다.
- 가급적이면 생산 데이터에 대한 모델의 예측에 대한 정기적인 수동 감사를 실시합니다. 일반적으로 데이터 주석과 동일한 인프라를 재사용할 수 있습니다. 생산 데이터의 일부를 수동으로 주석을 달도록 전송하고 모델의 예측값을 새 주석과 비교합니다.
- 수작업 감사가 불가능할 경우 사용자 설문조사 등 대안적 평가 방법(예: 스팸 및 공격적인 콘텐츠 플래그 지정 시스템)을 고려할 수 있습니다.

## 3.4 Maintain your model 

마지막으로, 영원한 모델은 없습니다. 컨셉 드리프트에 대해 이미 배웠습니다. 시간이 지남에 따라 생산 데이터의 특성이 바뀌어 모델의 성능과 관련성이 점차 저하됩니다.모델이 출시되자마자 모델을 대체할 다음 세대를 교육할 준비를 해야 합니다.

- 생산 데이터의 변화를 주의합니다. 새로운 기능을 사용할 수 있는지, 레이블 세트를 확장해야 하는지, 그렇지 않으면 편집해야 하는지를 고려합니다.
- 데이터를 계속 수집하고 주석을 달 수 있으며, 시간이 지남에 따라 주석 파이프라인을 계속 개선할 수 있습니다. 특히 현재 모형에 대해 분류하기 어려운 표본을 수집하는 데 특히 주의해야 합니다. 이러한 표본은 성능을 향상시키는 데 도움이 될 가능성이 높습니다. 

이것으로 머신러닝의 보편적인 작업 흐름을 마무리합니다. 이제 기계 학습 프로젝트에 수반되는 전체 스펙트럼이라는 큰 그림에 익숙해졌습니다. 모델 개발 부분은 워크플로우의 일부분에 불과하다는 것을 알게 되었습니다. 항상 큰 그림을 명심해야 합니다.
