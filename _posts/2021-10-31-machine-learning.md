---
layout: single
title: "Workflow of machine learning"
excerpt: "The process of dealing with machine learning problems."

toc: true
toc_sticky: true

date: 2021-10-31
---

'The universal workflow of machine learning'에서는 머신러닝에 접근하고 문제를 해결하는 데 사용할 수 있는 보편적인 단계에 대해 알아보겠습니다.

머신러닝의 보편적 워크플로는 크게 세 부분으로 구성됩니다.

- 문제의 정의: 문제 영역과 고객이 질문한 내용을 뒷받침하는 비즈니스 논리를 이해합니다. 데이터 세트를 수집하고, 데이터가 나타내는 바를 파악한 후, 작업에서 성공을 측정하는 방법을 선택합니다.
- 모델 개발: 머신러닝 모델에서 데이터를 처리할 수 있도록 준비하고, 모델 평가 프로토콜과 이길 수 있는 간단한 기준선을 선택한 다음, 오버핏할 수 있는 일반화 능력을 갖춘 첫 번째 모델을 교육한 다음, 최대한의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정합니다.
- 모델 배치: 이해 관계자에게 작업물을 전달하고, 여러 종류의 장치로 모델을 전달하며, 모델 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집합니다.

## 1. Define the task

### 1.1 Frame the problem 

기계 학습 문제를 구체화하려면 일반적으로 이해관계자들과의 많은 상세한 논의가 필요합니다. 이 과정에서 필요한 질문들이 있습니다.

- 입력 데이터는 어떻게 되는가? 무엇을 예측하려고 하는가? 이 단계에서 데이터 가용성은 보통 제한 요소입니다. 대부분의 경우 사용자가 직접 새 데이터셋을 수집하고 주석을 달아야 합니다.
- 어떤 종류의 기계 학습 문제인가? (이항 분류, 다중 클래스 분류, 스칼라 회귀, 벡터 회귀, 멀티클래스, 멀티라벨 분류, 이미지 분할, 순위, 클러스터링, 생성 또는 강화 학습 등)
- 기존 솔루션은 어떤 형태인가? 현재 일부 분야에서는 인간이 직접 처리하는 과정 등의 수작업 알고리즘을 거칠 것입니다. 어떤 시스템이 이미 구축되어 있는지, 어떻게 작동하는지 확실히 이해해야 합니다.
- 처리해야 할 특별한 제약이 있는가? 우리는 모델이 들어맞을 전체 맥락을 이해해야 합니다.

일단 조사를 마쳤으면, 여러분의 입력이 무엇일지, 여러분의 목표가 무엇인지, 그리고 문제가 어떤 종류의 기계 학습 과제로 매핑되는지 알아야 합니다. 이 단계에서 자신이 세우는 가설에 유의하여야 합니다.

- 입력이 주어지면 목표값을 예측할 수 있다는 가설을 세웁니다.
- 사용할 수 있는 데이터(또는 곧 수집할 데이터)가 입력과 목표값 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다.

작업 모형을 갖추기 전까지는 가설일 뿐이며 검증되거나 무효화될 수 있습니다. 기계 학습으로 모든 문제를 해결할 수 있는 것은 아닙니다. 입력 X와 대상 Y의 예를 종합했다고 해서 X가 Y를 예측하기에 충분한 정보를 포함하고 있다는 것이 아니라는 의미입니다. 

### 1.2 Collect a dataset 

작업의 특성을 이해하고 입력과 대상이 무엇인지 알게 되면, 다음은 시간과 비용이 많이 드는 부분인 데이터 수집이 필요한 시점입니다.

모델의 일반화 기능은 거의 전적으로 모델의 데이터 속성, 즉 보유한 데이터 포인트 수, 레이블의 안정성, 기능의 품질에 따라 정해집니다. 좋은 데이터 세트는 관리하고 투자할 가치가 있는 자산이라고 볼 수 있습니다.

지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후에는 입력(예: 이미지 태그)에 대한 주석(예: 모델이 예측할 목표)이 필요합니다.

**Investing in data-annotation infrastructure

데이터 주석 공정에 따라 목표물의 품질이 결정되고, 이는 다시 모형의 품질을 결정합니다. 사용할 수 있는 옵션을 신중하게 고려하여야 합니다.

- 데이터에 직접 주석을 달아야 하는가.
- 라벨을 모으기 위해 기계 터크와 같은 크라우드소싱 플랫폼을 사용해야 하는가?
- 데이터 레이블링 전문 회사의 서비스를 사용해야 하는가?

아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제력을 잃게 될 수 있습니다. 
최상의 옵션을 선택하려면 작업 중인 제약 조건을 고려해야 합니다.

- 데이터 라벨 작성자가 주제 전문가여야 하는가, 아니면 데이터에 주석을 달 수 있는 사람이 있는가
- 데이터에 주석을 달아야 하는 전문 지식이 있다면, 그것을 하도록 사람들을 훈련시킬 수 있는가? 그렇지 않다면, 관련 전문가와 어떻게 접촉할 수 있는가?
- 당신은 전문가들이 어떻게 주석을 달 수 있는지 이해하는가? 그렇지 않으면 데이터 세트를 블랙박스로 취급해야 하며 수동 기능 엔지니어링을 수행할 수 없습니다.

데이터에 레이블을 붙이기로 결정한 경우 주석을 기록하는 데 사용할 소프트웨어를 확인하여야 합니다. 직접 그 소프트웨어를 개발해야 할 경우를 대비하기 위함입니다. 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있습니다.

**Beware of non-representative data 

기계 학습 모델은 교육에 사용되는 데이터가 생산 데이터를 대표해야 합니다.
가능하면 모델이 사용될 환경에서 직접 데이터를 수집합니다. 프로덕션 데이터에 대한 교육이 가능하지 않다면 교육 데이터와 프로덕션 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 합니다.

알아야 할 관련 현상은 개념 드리프트입니다. 거의 모든 실제 문제, 특히 사용자 생성 데이터를 다루는 문제에서 개념 드리프트가 발생합니다. 개념 드리프트는 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생합니다. 빠른 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석 및 모델 재교육이 필요합니다. 기계 학습은 훈련 데이터에 존재하는 패턴을 암기하는 데만 사용될 수 있다는 것을 명심하여야 합니다. 전에 본 것만 알아볼 수 있다는 의미이다. 미래를 예측하기 위해 과거 데이터에 대해 훈련된 머신러닝을 사용하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 하는 것이며 이러한 경향은 틀릴 가능성이 있습니다.

### 1.3 Understand your data 

데이터 세트를 블랙박스로 취급하는 것은 매우 나쁜 관행입니다. 모델을 교육하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고(기능 엔지니어링에 정보를 제공) 잠재적인 문제를 선별해야 합니다.

- 데이터에 이미지 또는 자연어 텍스트가 포함된 경우 몇 가지 샘플(및 해당 레이블)을 직접 살펴보기
- 데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악
- 데이터에 위치 정보가 포함되어 있으면 지도에 표시하여 뚜렷한 패턴이 있는 지 확인
- 일부 샘플에 일부 기능의 결측값이 있는지 확인 (이 경우 데이터를 준비할 때 이 문제를 해결해야 합니다)
- 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 출력. 클래스가 대략적으로 동등하게 표현되지않다면 불균형을 고려해야 합니다. 
- 목표 누출 여부: 데이터에 실운영 환경에서 사용할 수 없는 대상에 대한 정보를 제공하는 기능이 있는지 확인. 데이터의 모든 기능이 운영 환경에서도 동일한 형태로 제공되는지 확인하여야 합니다.

### 1.4 Choose a measure of success

무언가를 통제하기 위해서는 그것을 관찰할 수 있어야 합니다. 프로젝트에서 성공을 거두기 위해서는 먼저 성공의 기준을 정의해야 합니다. (정확성? 정확성과 기억력? 고객 유지율?) 성공을 위한 지표는 프로젝트 전반에 걸쳐 진행될 될 모든 기술적 선택의 기준이 될 것입니다. 고객의 비즈니스 성공과 같은 상위 수준의 목표와 직접 연계되어야 합니다. 

모든 클래스가 동일한 가능성이 있는 균형 분류 문제의 경우, 수신기 작동 특성 곡선(ROC AUC) 아래의 정확도와 영역이 일반적인 지표입니다. 클래스 불균형 문제, 순위 문제 또는 다중 레이블 분류의 경우 정밀도 및 호출뿐만 아니라 가중 형태의 정확도 또는 ROC AUC를 사용할 수 있습니다. 또한 성공을 측정하기 위해 자신만의 사용자 지정 메트릭을 정의해야 하는 경우도 흔합니다. 

## 2. Develop a model 

### 2.1 Prepare the data 

딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않습니다. 데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것입니다. 여기에는 벡터화, 정규화 또는 결측값 처리가 포함됩니다. 모든 데이터 도메인에 공통적으로 적용되는 기본 사항에 대해 살펴보겠습니다.

**Vectorization

신경망의 모든 입력과 대상은 일반적으로 부동소수점 데이터의 텐서(또는 특정한 경우 정수나 문자열의 텐서)여야 합니다. 소리, 이미지, 텍스트 등 필요한 데이터가 무엇이든 먼저 텐서로 변환해야 합니다. 이 단계를 데이터 벡터화라고 합니다. 예를 들어, 두 텍스트 분류 예에서는 정수 목록(단어 시퀀스를 나타냄)으로 표현된 텍스트에서 원핫 인코딩을 사용하여 float32 데이터의 텐서로 변환합니다.

**Value normalization

데이터를 네트워크에 입력하기 전에 표준 편차가 1이고 평균이 0이 되도록 각 피쳐를 독립적으로 정규화합니다. 
일반적으로 상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 사용하는 신경망 데이터나 다종의 데이터(예: 한 특징이 0-1이고 다른 특징이 100-200인 데이터)에 입력하는 것은 좋지 않습니다. 이렇게 하면 대규모 그라데이션 업데이트가 트리거되어 네트워크가 수렴되지 않을 수 있습니다. 네트워크에서 보다 쉽게 학습하려면 데이터에 다음과 같은 특성이 있어야 합니다.

- 작은 값 사용: 일반적으로 대부분의 값은 0-1 범위여야 합니다. 
- 동일화: 모든 형상이 거의 동일한 범위의 값을 가져야 합니다. 

추가적으로 다음과 같은 엄격한 정규화 방법이 일반적입니다. (항상 필요한 것은 아니지만 도움이 될 수 있습니다.)

- 평균이 o가 되도록 각 피쳐를 독립적으로 정규화합니다. 
- 표준 편차가 1이 되도록 각 피쳐를 독립적으로 정규화합니다.

Handling missing values 
때때로 데이터에 결측값이 있을 수 있습니다. 예를 들어, 집값의 예에서 첫 번째 특징(데이터의 지수 0 열)은 1인당 범죄율이었다. 만약 이 기능이 모든 샘플에서 사용할 수 없다면요? 그러면 교육 또는 검정 데이터에 결측값이 있게 됩니다. 

기능을 완전히 폐기할 수도 있지만 반드시 폐기할 필요는 없습니다. 
- 피쳐가 범주형인 경우 "값이 누락되었습니다"를 의미하는 새 범주를 만드는 것이 안전합니다. 모델은 대상에 대해 이것이 내포하는 의미를 자동으로 학습한다. 
- 만약 형상이 수치적이라면, "0"과 같은 임의의 값을 입력하지 마세요. 왜냐하면 형상에 의해 형성된 잠재 공간에 불연속성이 생성되어, 그것에 대해 훈련된 모델이 일반화하기가 더 어려울 수 있기 때문입니다. 대신 결측값을 데이터 집합의 기능에 대한 평균값 또는 중위값으로 바꾸는 것을 고려하십시오. 다른 형상의 값이 주어진 형상의 값을 예측하도록 모델을 교육할 수도 있습니다.

테스트 데이터에 범주형 결측 기능이 있을 것으로 예상되지만 네트워크가 결측값 없이 데이터에 대해 학습된 경우, 네트워크는 결측값을 무시하는 방법을 배우지 않습니다. 이 경우 누락된 항목이 있는 교육 샘플을 인위적으로 생성해야 합니다. 일부 교육 샘플을 여러 번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 기능 중 일부를 삭제해야 합니다.
